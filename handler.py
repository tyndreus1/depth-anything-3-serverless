"""
Depth Anything 3 - RunPod Handler (Template Deployment)
Bu dosyayÄ± GitHub'a yÃ¼kleyip RunPod'dan direkt kullanacaÄŸÄ±z - Docker build'e gerek yok!
"""

import runpod
import torch
import base64
import io
import time
from PIL import Image
import numpy as np

# Model import
try:
    from depth_anything_3.api import DepthAnything3
    DEPTH_ANYTHING_AVAILABLE = True
except ImportError:
    print("âš ï¸ Depth Anything 3 henÃ¼z yÃ¼klenmedi, ilk Ã§alÄ±ÅŸtÄ±rmada yÃ¼klenecek...")
    DEPTH_ANYTHING_AVAILABLE = False

# Global deÄŸiÅŸkenler
MODEL = None
DEVICE = None

def install_dependencies():
    """Gerekli paketleri yÃ¼kle"""
    import subprocess
    import sys
    
    print("ğŸ“¦ BaÄŸÄ±mlÄ±lÄ±klar yÃ¼kleniyor...")
    
    packages = [
        "torch>=2.0.0",
        "torchvision>=0.15.0",
        "pillow>=9.0.0",
        "numpy>=1.24.0",
        "opencv-python-headless>=4.8.0",
        "timm>=0.9.0",
        "transformers>=4.30.0",
        "huggingface_hub>=0.16.0",
        "einops>=0.7.0",
        "git+https://github.com/ByteDance-Seed/Depth-Anything-3.git"
    ]
    
    for package in packages:
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", package])
            print(f"âœ“ {package.split('>=')[0]} yÃ¼klendi")
        except:
            print(f"âœ— {package} yÃ¼klenemedi, devam ediliyor...")

def load_model():
    """Model'i yÃ¼kle"""
    global MODEL, DEVICE, DEPTH_ANYTHING_AVAILABLE
    
    if MODEL is None:
        print("ğŸš€ Model yÃ¼kleniyor...")
        start_time = time.time()
        
        # EÄŸer depth_anything_3 yÃ¼klÃ¼ deÄŸilse, Ã¶nce yÃ¼kle
        if not DEPTH_ANYTHING_AVAILABLE:
            install_dependencies()
            from depth_anything_3.api import DepthAnything3
        
        DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ“ Device: {DEVICE}")
        
        # Model'i indir ve yÃ¼kle
        MODEL = DepthAnything3.from_pretrained("depth-anything/DA3-LARGE")
        MODEL = MODEL.to(device=DEVICE)
        MODEL.eval()
        
        elapsed = time.time() - start_time
        print(f"âœ… Model yÃ¼klendi ({elapsed:.2f} saniye)")
    
    return MODEL

def image_to_base64(image_array):
    """NumPy array'i base64'e Ã§evir"""
    depth_normalized = ((image_array - image_array.min()) / 
                       (image_array.max() - image_array.min()) * 255).astype(np.uint8)
    depth_image = Image.fromarray(depth_normalized)
    
    buffered = io.BytesIO()
    depth_image.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode()

def process_depth(job):
    """Ana iÅŸlem fonksiyonu"""
    try:
        job_input = job["input"]
        
        if "image" not in job_input:
            return {"error": "âŒ 'image' parametresi gerekli (base64 string)"}
        
        print(f"ğŸ“¥ Ä°ÅŸlem baÅŸlÄ±yor - Job ID: {job['id']}")
        start_time = time.time()
        
        # Model yÃ¼kle
        model = load_model()
        
        # Ä°majÄ± decode et
        image_data = base64.b64decode(job_input["image"])
        image = Image.open(io.BytesIO(image_data)).convert("RGB")
        print(f"ğŸ“¸ Ä°maj boyutu: {image.size}")
        
        # Depth map oluÅŸtur
        inference_start = time.time()
        with torch.no_grad():
            prediction = model.inference([image])
        inference_time = time.time() - inference_start
        
        # Sonucu hazÄ±rla
        depth_map = prediction.depth[0]
        depth_base64 = image_to_base64(depth_map)
        
        total_time = time.time() - start_time
        print(f"âœ… TamamlandÄ± - Ä°nference: {inference_time:.2f}s, Toplam: {total_time:.2f}s")
        
        return {
            "depth_map": depth_base64,
            "original_size": list(image.size),
            "depth_shape": list(depth_map.shape),
            "inference_time": round(inference_time, 2),
            "total_time": round(total_time, 2),
            "success": True
        }
        
    except Exception as e:
        print(f"âŒ Hata: {str(e)}")
        import traceback
        traceback.print_exc()
        return {"error": str(e), "success": False}

# RunPod baÅŸlangÄ±Ã§
if __name__ == "__main__":
    print("ğŸ¯ Depth Anything 3 Serverless baÅŸlatÄ±lÄ±yor...")
    runpod.serverless.start({"handler": process_depth})
