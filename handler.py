"""
Depth Anything 3 - RunPod Serverless Handler
Bu dosya RunPod serverless endpoint'te Ã§alÄ±ÅŸacak ana kod
"""

import runpod
import torch
import base64
import io
import time
from PIL import Image
import numpy as np
from depth_anything_3.api import DepthAnything3

# Global model - Sadece bir kez yÃ¼klenir (cold start'ta)
MODEL = None
DEVICE = None

def load_model():
    """Model'i yÃ¼kle (sadece ilk Ã§aÄŸrÄ±da)"""
    global MODEL, DEVICE
    
    if MODEL is None:
        print("ğŸš€ Model yÃ¼kleniyor...")
        start_time = time.time()
        
        DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ“ Device: {DEVICE}")
        
        # Model'i indir ve yÃ¼kle
        MODEL = DepthAnything3.from_pretrained("depth-anything/DA3-LARGE")
        MODEL = MODEL.to(device=DEVICE)
        MODEL.eval()  # Inference mode
        
        elapsed = time.time() - start_time
        print(f"âœ… Model yÃ¼klendi ({elapsed:.2f} saniye)")
    
    return MODEL


def image_to_base64(image_array):
    """NumPy array'i base64 string'e Ã§evir"""
    # Normalize depth map (0-255 arasÄ±)
    depth_normalized = ((image_array - image_array.min()) / 
                       (image_array.max() - image_array.min()) * 255).astype(np.uint8)
    
    # PIL Image'e Ã§evir
    depth_image = Image.fromarray(depth_normalized)
    
    # Base64'e encode et
    buffered = io.BytesIO()
    depth_image.save(buffered, format="PNG")
    img_base64 = base64.b64encode(buffered.getvalue()).decode()
    
    return img_base64


def process_depth(job):
    """
    Ana iÅŸlem fonksiyonu
    RunPod bu fonksiyonu her istek iÃ§in Ã§aÄŸÄ±rÄ±r
    """
    try:
        job_input = job["input"]
        
        # Input validasyonu
        if "image" not in job_input:
            return {"error": "âŒ 'image' parametresi gerekli (base64 string)"}
        
        print(f"ğŸ“¥ Ä°ÅŸlem baÅŸlÄ±yor - Job ID: {job['id']}")
        start_time = time.time()
        
        # Model'i yÃ¼kle (ilk Ã§aÄŸrÄ±da)
        model = load_model()
        
        # Base64 imajÄ± decode et
        image_data = base64.b64decode(job_input["image"])
        image = Image.open(io.BytesIO(image_data)).convert("RGB")
        
        print(f"ğŸ“¸ Ä°maj boyutu: {image.size}")
        
        # Depth map oluÅŸtur
        inference_start = time.time()
        
        with torch.no_grad():
            prediction = model.inference([image])
        
        inference_time = time.time() - inference_start
        
        # Sonucu base64'e Ã§evir
        depth_map = prediction.depth[0]  # Ä°lk imajÄ±n depth map'i
        depth_base64 = image_to_base64(depth_map)
        
        # Toplam sÃ¼re
        total_time = time.time() - start_time
        
        print(f"âœ… Ä°ÅŸlem tamamlandÄ± - Ä°nference: {inference_time:.2f}s, Toplam: {total_time:.2f}s")
        
        # Sonucu dÃ¶ndÃ¼r
        return {
            "depth_map": depth_base64,
            "original_size": list(image.size),
            "depth_shape": list(depth_map.shape),
            "inference_time": round(inference_time, 2),
            "total_time": round(total_time, 2),
            "success": True
        }
        
    except Exception as e:
        print(f"âŒ Hata: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return {
            "error": str(e),
            "success": False
        }


# RunPod serverless baÅŸlangÄ±Ã§ noktasÄ±
if __name__ == "__main__":
    print("ğŸ¯ Depth Anything 3 Serverless baÅŸlatÄ±lÄ±yor...")
    runpod.serverless.start({"handler": process_depth})