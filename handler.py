"""
Depth Anything 3 - RunPod Serverless Handler (Self-Contained)
Bu handler kendi baÅŸÄ±na Ã§alÄ±ÅŸÄ±r - GitHub clone ve package install yapar
"""

import os
import sys
import subprocess
import time

def setup_environment():
    """OrtamÄ± hazÄ±rla: Git clone + pip install"""
    
    print("=" * 60)
    print("ğŸš€ Depth Anything 3 Kurulum BaÅŸlÄ±yor...")
    print("=" * 60)
    
    # Workspace dizini
    workspace = "/workspace"
    repo_dir = os.path.join(workspace, "depth-anything-repo")
    
    # 1. Git clone (eÄŸer yoksa)
    if not os.path.exists(repo_dir):
        print("ğŸ“¦ GitHub repository clone ediliyor...")
        try:
            subprocess.check_call([
                "git", "clone",
                "https://github.com/tyndreus1/depth-anything-3-serverless.git",
                repo_dir
            ])
            print("âœ… Clone tamamlandÄ±!")
        except subprocess.CalledProcessError as e:
            print(f"âŒ Git clone baÅŸarÄ±sÄ±z: {e}")
            return False
    else:
        print("âœ… Repository zaten mevcut")
    
    # 2. Requirements.txt'i kur
    requirements_path = os.path.join(repo_dir, "requirements.txt")
    if os.path.exists(requirements_path):
        print("ğŸ“¦ Python paketleri kuruluyor...")
        try:
            subprocess.check_call([
                sys.executable, "-m", "pip", "install",
                "--no-cache-dir", "--ignore-installed",
                "-r", requirements_path
            ])
            print("âœ… Paketler kuruldu!")
        except subprocess.CalledProcessError as e:
            print(f"âŒ Pip install baÅŸarÄ±sÄ±z: {e}")
            return False
    
    # 3. RunPod SDK'yÄ± kur
    print("ğŸ“¦ RunPod SDK kuruluyor...")
    try:
        subprocess.check_call([
            sys.executable, "-m", "pip", "install",
            "--no-cache-dir", "--ignore-installed", "runpod"
        ])
        print("âœ… RunPod SDK kuruldu!")
    except subprocess.CalledProcessError as e:
        print(f"âŒ RunPod install baÅŸarÄ±sÄ±z: {e}")
        return False
    
    print("=" * 60)
    print("âœ… Kurulum tamamlandÄ±!")
    print("=" * 60)
    
    return True

# Kurulum yap
if not setup_environment():
    print("âŒ Kurulum baÅŸarÄ±sÄ±z, Ã§Ä±kÄ±lÄ±yor...")
    sys.exit(1)

# Åimdi gerÃ§ek handler'Ä± import et ve Ã§alÄ±ÅŸtÄ±r
import runpod
import torch
import base64
import io
from PIL import Image
import numpy as np
from depth_anything_3.api import DepthAnything3

# Global deÄŸiÅŸkenler
MODEL = None
DEVICE = None

def load_model():
    """Model'i yÃ¼kle"""
    global MODEL, DEVICE
    
    if MODEL is None:
        print("ğŸš€ Model yÃ¼kleniyor...")
        start_time = time.time()
        
        DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ“ Device: {DEVICE}")
        
        MODEL = DepthAnything3.from_pretrained("depth-anything/DA3-LARGE")
        MODEL = MODEL.to(device=DEVICE)
        MODEL.eval()
        
        elapsed = time.time() - start_time
        print(f"âœ… Model yÃ¼klendi ({elapsed:.2f} saniye)")
    
    return MODEL

def image_to_base64(image_array):
    """NumPy array'i base64'e Ã§evir"""
    depth_normalized = ((image_array - image_array.min()) / 
                       (image_array.max() - image_array.min()) * 255).astype(np.uint8)
    depth_image = Image.fromarray(depth_normalized)
    
    buffered = io.BytesIO()
    depth_image.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode()

def process_depth(job):
    """Ana iÅŸlem fonksiyonu"""
    try:
        job_input = job["input"]
        
        if "image" not in job_input:
            return {"error": "âŒ 'image' parametresi gerekli (base64 string)"}
        
        print(f"ğŸ“¥ Ä°ÅŸlem baÅŸlÄ±yor - Job ID: {job['id']}")
        start_time = time.time()
        
        # Model yÃ¼kle
        model = load_model()
        
        # Ä°majÄ± decode et
        image_data = base64.b64decode(job_input["image"])
        image = Image.open(io.BytesIO(image_data)).convert("RGB")
        print(f"ğŸ“¸ Ä°maj boyutu: {image.size}")
        
        # Depth map oluÅŸtur
        inference_start = time.time()
        with torch.no_grad():
            prediction = model.inference([image])
        inference_time = time.time() - inference_start
        
        # Sonucu hazÄ±rla
        depth_map = prediction.depth[0]
        depth_base64 = image_to_base64(depth_map)
        
        total_time = time.time() - start_time
        print(f"âœ… TamamlandÄ± - Ä°nference: {inference_time:.2f}s, Toplam: {total_time:.2f}s")
        
        return {
            "depth_map": depth_base64,
            "original_size": list(image.size),
            "depth_shape": list(depth_map.shape),
            "inference_time": round(inference_time, 2),
            "total_time": round(total_time, 2),
            "success": True
        }
        
    except Exception as e:
        print(f"âŒ Hata: {str(e)}")
        import traceback
        traceback.print_exc()
        return {"error": str(e), "success": False}

# RunPod baÅŸlat
if __name__ == "__main__":
    print("ğŸ¯ Depth Anything 3 Serverless baÅŸlatÄ±lÄ±yor...")
    runpod.serverless.start({"handler": process_depth})
